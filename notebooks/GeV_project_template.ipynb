{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHYS2015A/PHYS3009A: GeV Astronomy Project\n",
    "\n",
    "Name: \n",
    "\n",
    "Student No.:\n",
    "\n",
    "total marks: 88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project you will do yourself the data analysis of the Small Magellanic Cloud (SMC). You mainly need to copy and paste code from the PKS2155-304 notebook which we have discussed in the lecture, and make the necessary changes for the new source. You will be provided with example output so that you can check your results. Please put your code in the cells starting with \n",
    "\n",
    "```\n",
    "# your code here\n",
    "```\n",
    "\n",
    "There will also be exercises where you must answer questions inside the markdown cell. Pleas put your answer where it says\n",
    "\n",
    "*-* your answer here\n",
    "\n",
    "You do not need to edit any other cells. If you want to add additional output, or test some things you can create new cells for that.\n",
    "\n",
    "If there are any discrepancies between the text and output, and you wish to align the code with the text, feel free to do so; just add a new cell explaining your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Let's start with importing some of the modules we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from fermipy.gtanalysis import GTAnalysis\n",
    "from fermipy.plotting import ROIPlotter, SEDPlotter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "\n",
    "We could obtain the raw data files from the [Fermi SSC website](https://fermi.gsfc.nasa.gov/cgi-bin/ssc/LAT/LATDataQuery.cgi). The following data selection choices were made:\n",
    "\n",
    "* Object name or coordinates: 302.25,-44.37\n",
    "* Coordinate system: GAL\n",
    "* Search radius (degrees): 12\n",
    "* Observation dates: 239557417,512994417\n",
    "* Time system: MET\n",
    "* Energy range (MeV): 100,500000\n",
    "* LAT data type: Photon\n",
    "* Spacecraft data: yes\n",
    "\n",
    "The raw data with these selections can be downloaded using wget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up a subdirectory for the data\n",
    "# !mkdir -p SMC_data/PH\n",
    "# !mkdir -p SMC_data/SC\n",
    "\n",
    "# # Download the data and place into the subdirectory\n",
    "# !wget -P ./SMC_data/PH/ https://fermi.gsfc.nasa.gov/FTP/fermi/data/lat/queries/L240613164330AE56FF4635_PH00.fits\n",
    "# !wget -P ./SMC_data/PH/ https://fermi.gsfc.nasa.gov/FTP/fermi/data/lat/queries/L240613164330AE56FF4635_PH01.fits\n",
    "# !wget -P ./SMC_data/PH/ https://fermi.gsfc.nasa.gov/FTP/fermi/data/lat/queries/L240613164330AE56FF4635_PH02.fits\n",
    "# !wget -P ./SMC_data/PH/ https://fermi.gsfc.nasa.gov/FTP/fermi/data/lat/queries/L240613164330AE56FF4635_PH03.fits\n",
    "# !wget -P ./SMC_data/PH/ https://fermi.gsfc.nasa.gov/FTP/fermi/data/lat/queries/L240613164330AE56FF4635_PH04.fits\n",
    "# !wget -P ./SMC_data/PH/ https://fermi.gsfc.nasa.gov/FTP/fermi/data/lat/queries/L240613164330AE56FF4635_PH05.fits\n",
    "# !wget -P ./SMC_data/PH/ https://fermi.gsfc.nasa.gov/FTP/fermi/data/lat/queries/L240613164330AE56FF4635_PH06.fits\n",
    "\n",
    "# !wget -P ./SMC_data/SC/ https://fermi.gsfc.nasa.gov/FTP/fermi/data/lat/queries/L240613164330AE56FF4635_SC00.fits\n",
    "\n",
    "# # Make a file list\n",
    "# !ls ./SMC_data/PH/*PH*.fits > ./SMC_data/PH.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that processing the raw photon and spacecraft files can take multiple hours. Instead, we will download the pre-processed data from github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.isfile('./../data/SMC_data.tar.gz'):\n",
    "    !tar xzf ./../data/SMC_data.tar.gz\n",
    "else:\n",
    "    !wget -P ./../data/ https://raw.githubusercontent.com/fermiPy/fermipy-extras/master/data/SMC_data.tar.gz\n",
    "    !tar xzf ./../data/SMC_data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to compose a configuration file that defines the data selection and analysis parameters. Fermipy uses YAML files to read and write its configuration in a persistent format. The configuration file has a hierarchical structure that groups parameters into dictionaries that are keyed to a section name (data, binning, etc.). Let's look at the contents of the included `config.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./SMC_data/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration file has the same structure as the configuration dictionary such that one can read/write configurations using the load/dump methods of the yaml module.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Use the 'yaml' module to load the config file into a structure called 'config'.\n",
    "Then replace the 'emin' parameter in the 'selection' section with 1000.\n",
    "Finally, dump the new configuration into a yaml file called 'new_config.yaml'\n",
    "\n",
    "**[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# your code here\n",
    "\n",
    "!cat new_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "* What does the `data` section define?\n",
    "  * What does the `evfile` point to? What do the files encompass?\n",
    "  * What do the parameters in the `binning` section define?\n",
    "* What parameters does the `selection` section define? \n",
    "  * What does the target parameter in this section define?\n",
    "* What parameters does the `model` section define?\n",
    "\n",
    "*-* **your answer here**\n",
    "\n",
    "**[7 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start your run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all you need to load the configuration file, create the object gta and run the tool gta.setup that implements the ST gtselect, gtmktime, gtbin, gtexpcube, gtsrcmap tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin the setup routine. As most of the files are included, only the source-map should be created. Will take ~5min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta = GTAnalysis('new_config.yaml')\n",
    "gta.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta.print_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All sources have `ts=nan` because we have not done yet a fit to the ROI. Moreover in the model above all sources are fixed. \n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Free all the sources in the model. Then perform the fit to the ROI.\n",
    "\n",
    "**[2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current state of the ROI can be written at any point by calling write_roi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta.write_roi('initial',make_plots=True,save_model_map=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output file will contain all information about the state of the ROI as calculated up to that point in the analysis including model parameters and measured source characteristics (flux, TS, NPred). An XML model file will also be saved for each analysis component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output file can be read with load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta.load_roi('initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using gta.print_model You have an overview of the sources and components present in the ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta.print_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sources dictionary contains one element per source keyed to the source name. It is possible to have access to a lot of information concerning each source of model.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "For the first source in the ROI (index = 0), print its name.\n",
    "Use the name as an index to the ROI to print out its information.\n",
    "Finally, print out separately its galactic coordinates, its flux, and the predicted number of counts.\n",
    "\n",
    "**[6 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other possible outputs are listed here [fermipy/sourcedictionary](http://fermipy.readthedocs.io/en/latest/output.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta.free_shape(gta.roi.sources[0].name,free=False) #Free or fix the index\n",
    "gta.get_free_source_params(gta.roi.sources[0].name) #Free or fix parameters for a source\n",
    "gta.set_parameter(gta.roi.sources[0].name,par='Index',value=-2.0,scale=-1.0,bounds=[-2.,5.]) #Change the value and bounds for a parameter of a source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always use gta.print_model() to have a summary of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta.print_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROIModel class is responsible for managing the source and diffuse components in the ROI. Configuration of the model is controlled with the model block of YAML configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIFFUSE AND ISOTROPIC TEMPLATES\n",
    "\n",
    "The simplest configuration uses a single file for the galactic and isotropic diffuse components. By default the galactic diffuse and isotropic components will be named galdiff and isodiff respectively. An alias for each component will also be created with the name of the mapcube or file spectrum. For instance the galactic diffuse can be referred to as galdiff or gll_iem_v06 in the following example."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model:\n",
    "  src_roiwidth : 10.0\n",
    "  galdiff  : '$FERMI_DIFFUSE_DIR/gll_iem_v06.fits'\n",
    "  isodiff  : '$FERMI_DIFFUSE_DIR/isotropic_source_4years_P8V3.txt'\n",
    "  catalogs : ['gll_psc_v14.fit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define two or more galactic diffuse components you can optionally define the galdiff and isodiff parameters as lists. A separate component will be generated for each element in the list with the name galdiffXX or isodiffXX where XX is an integer position in the list."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model:\n",
    "  galdiff  :\n",
    "    - '$FERMI_DIFFUSE_DIR/diffuse_component0.fits'\n",
    "    - '$FERMI_DIFFUSE_DIR/diffuse_component1.fits'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOURCE COMPONENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of sources for inclusion in the ROI model is set by defining a list of catalogs with the catalogs parameter. Catalog files can be in either XML or FITS format. Sources from the catalogs in this list that satisfy either the src_roiwidth or src_radius selections are added to the ROI model. If a source is defined in multiple catalogs the source definition from the last file in the catalogs list takes precedence."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model:\n",
    "\n",
    "  src_radius: 5.0\n",
    "  src_roiwidth: 10.0\n",
    "  catalogs :\n",
    "    - 'gll_psc_v16.fit'\n",
    "    - 'extra_sources.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual sources can also be defined within the configuration file with the sources parameter. This parameter contains a list of dictionaries that defines the spatial and spectral parameters of each source. The keys of the source dictionary map to the spectral and spatial source properties as they would be defined in the XML model file."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model:\n",
    "  sources  :\n",
    "    - { name: 'SourceA', glon : 120.0, glat : -3.0,\n",
    "     SpectrumType : 'PowerLaw', Index : 2.0, Scale : 1000, Prefactor : !!float 1e-11,\n",
    "     SpatialModel: 'PointSource' }\n",
    "    - { name: 'SourceB', glon : 122.0, glat : -3.0,\n",
    "     SpectrumType : 'LogParabola', norm : !!float 1E-11, Scale : 1000, beta : 0.0,\n",
    "     SpatialModel: 'PointSource' }\n",
    "model:\n",
    "  sources  :\n",
    "    - { name: 'PointSource', glon : 120.0, glat : 0.0,\n",
    "     SpectrumType : 'PowerLaw', Index : 2.0, Scale : 1000, Prefactor : !!float 1e-11,\n",
    "     SpatialModel: 'PointSource' }\n",
    "    - { name: 'DiskSource', glon : 120.0, glat : 0.0,\n",
    "     SpectrumType : 'PowerLaw', Index : 2.0, Scale : 1000, Prefactor : !!float 1e-11,\n",
    "     SpatialModel: 'RadialDisk', SpatialWidth: 1.0 }\n",
    "    - { name: 'GaussSource', glon : 120.0, glat : 0.0,\n",
    "     SpectrumType : 'PowerLaw', Index : 2.0, Scale : 1000, Prefactor : !!float 1e-11,\n",
    "     SpatialModel: 'RadialGaussian', SpatialWidth: 1.0 }\n",
    "    - { name: 'MapSource', glon : 120.0, glat : 0.0,\n",
    "     SpectrumType : 'PowerLaw', Index : 2.0, Scale : 1000, Prefactor : !!float 1e-11,\n",
    "     SpatialModel: 'SpatialTemplate', Spatial_Filename : 'template.fits' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can do it while you are running your script.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Delete the first source in the ROI\n",
    "Extract the galactic coordinates of the source as defined in the `config` object.\n",
    "Add a new source, called \"SMC\", with those coordinates, a \"PowerLaw\" SpectrumType, a spectral index with value -2.4 and bounds [-1.,-5], a scale with value 1e3 and bounds [1,1e5], and a prefactor with value 1.0, scale 1e-13, and bounds [1e-4,1e]. Set it to be free, initialize the source, and save the source map.\n",
    "\n",
    "**[9 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "gta.print_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to free only the sources that are at a certain angular distance from a source. For example below we free the sources that are 2 degrees away from 3FGL J0059.0-7242e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta.free_sources(free=False)\n",
    "gta.free_sources(skydir=gta.roi[gta.roi.sources[0].name].skydir,distance=[3.0],free=True)\n",
    "gta.print_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source fitting with fermipy is generally performed with the optimize and fit methods.\n",
    "fit is a wrapper on the pyLikelihood fit method and performs a likelihood fit of all free parameters of the model. This method can be used to manually optimize of the model by calling it after freeing one or more source parameters.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Free all the sources, then perform a fit, saving the result into an object called `first_fit`. Print the model. Then write the ROI into a file called `SMC_firstfit`, specifying that plost should be made and the model map saved.\n",
    "\n",
    "**[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default fit will repeat the fit until a fit quality of 3 is obtained. After the fit returns all sources with free parameters will have their properties (flux, TS, NPred, etc.) updated in the ROIModel instance. The return value of the method is a dictionary containing the following diagnostic information about the fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Print out the quality of the fit, the errors, the logLikelihood, and the values obtained.\n",
    "\n",
    "For the first source, print out the names, values, and errors of the parameters.\n",
    "\n",
    "**[7 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta.load_roi('initial')\n",
    "gta.print_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta.load_roi('SMC_firstfit')\n",
    "gta.print_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Has replacing the first source improved its statistical significance? How can you tell?\n",
    "\n",
    "*-* **your answer here**\n",
    "\n",
    "**[2 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TS Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tsmap() generates a test statistic (TS) map for an additional source component centered at each spatial bin in the ROI. The methodology is similar to that of the gttsmap ST application but with the following approximations:\n",
    "\n",
    "* Evaluation of the likelihood is limited to pixels in the vicinity of the test source position.\n",
    "* The background model is fixed when fitting the test source amplitude.\n",
    "\n",
    "TS Cube is a related method that can also be used to generate TS maps as well as cubes (TS vs. position and energy).\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Create a `tsmap` with prefix 'TSmap_start' and save it in an object called `tsmap_postfit`, specifying that plots should be made and both `npy` and `fits` files should be written.\n",
    "\n",
    "**[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ROIPlotter(tsmap_postfit['sqrt_ts'],roi=gta.roi).plot(levels=[0,3,5,7],vmin=0,vmax=5,subplot=121,cmap='magma')\n",
    "plt.gca().set_title('Sqrt(TS)')\n",
    "ROIPlotter(tsmap_postfit['npred'],roi=gta.roi).plot(vmin=0,vmax=100,subplot=122,cmap='magma')\n",
    "plt.gca().set_title('NPred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Looking to the TSmap, does is the model a good fit to the data? Why?\n",
    "\n",
    "*-* **your answer here**\n",
    "\n",
    "**[2 mark]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "residmap() calculates the residual between smoothed data and model maps. Whereas a TS map is only sensitive to positive deviations with respect to the model, residmap() is sensitive to both positive and negative residuals and therefore can be useful for assessing the model goodness-of-fit. \n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Generate a residual map named 'SMC_postfit', using a `PointSource SpatialModel` with `Index` 2.0, storing it in an object named `resid` while specifying that plots should be made and both `npy` and `fits` files should be written.\n",
    "\n",
    "**[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ROIPlotter(resid['data'],roi=gta.roi).plot(vmin=50,vmax=400,subplot=121,cmap='magma')\n",
    "plt.gca().set_title('Data')\n",
    "ROIPlotter(resid['model'],roi=gta.roi).plot(vmin=50,vmax=400,subplot=122,cmap='magma')\n",
    "plt.gca().set_title('Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ROIPlotter(resid['sigma'],roi=gta.roi).plot(vmin=-5,vmax=5,levels=[-5,-3,3,5],subplot=121,cmap='RdBu_r')\n",
    "plt.gca().set_title('Significance')\n",
    "ROIPlotter(resid['excess'],roi=gta.roi).plot(vmin=-100,vmax=100,subplot=122,cmap='RdBu_r')\n",
    "plt.gca().set_title('Excess')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The localize() method can be used to spatially localize a source. Localization is performed by scanning the likelihood surface in source position in a local patch around the nominal source position. The fit to the source position proceeds in two iterations:\n",
    "\n",
    "TS Map Scan: Obtain a first estimate of the source position by generating a likelihood map of the region using the tsmap method. In this step all background parameters are fixed to their nominal values. The size of the search region used for this step is set with the dtheta_max parameter.\n",
    "Likelihood Scan: Refine the position of the source by performing a scan of the likelihood surface in a box centered on the best-fit position found in the first iteration. The size of the search region is set to encompass the 99% positional uncertainty contour. This method uses a full likelihood fit at each point in the likelihood scan and will re-fit all free parameters of the model.\n",
    "If a peak is found in the search region and the positional fit succeeds, the method will update the position of the source in the model to the new best-fit position.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Fix all the sources in the model (i.e. set `free` to `False` for all the sources).\n",
    "\n",
    "Then free all the sources within 3 degrees of the first source.\n",
    "\n",
    "Finally, localize the first source in the ROI, storing the result in an object called `localsmc`, specifying that plots should be made and that the model should be updated with the new localization.\n",
    "\n",
    "Then print out the model.\n",
    "\n",
    "**[3 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "At what offset is the SMC localized?\n",
    "\n",
    "*-* **your answer here**\n",
    "\n",
    "Print out the galacitc coordinates, the radii of the 68%, 95%, and 99% position error circles, the semimajor and semiminor axes of the error ellipse, and the delta log Likelihood of the localization.\n",
    "\n",
    "**[8 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extension() method executes a source extension analysis for a given source by computing a likelihood ratio test with respect to the no-extension (point-source) hypothesis and a best-fit model for extension. The best-fit extension is found by performing a likelihood profile scan over the source width (68% containment) and fitting for the extension that maximizes the model likelihood. Currently this method supports two models for extension: a 2D Gaussian (RadialGaussian) or a 2D disk (RadialDisk).\n",
    "\n",
    "By default the method will fix all background parameters before performing the extension fit. One can leave background parameters free by setting free_background=True.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Fix all the sources in the model (i.e. set `free` to `False` for all the sources).\n",
    "\n",
    "Then free all the sources within 3 degrees of the first source.\n",
    "\n",
    "Finally, fit the extension of the first source in the ROI, storing the result in an object called `extensionsmc`, setting the spatial model to `RadialGaussian` and setting the `sqrt_ts_threshold` to 3.0, while specifying that plots should be made and that the model should be updated with the new extension.\n",
    "\n",
    "Then print out the model.\n",
    "\n",
    "**[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Print out the best fit value of the extension in degrees, the upper and lower errors, the symmetric error, the 95% upper limit, and the TS of the extension. \n",
    "\n",
    "Is the extension significant? Why?\n",
    "\n",
    "*-* **your answer here**\n",
    "\n",
    "**[8 marks]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_sources() is an iterative source-finding algorithm that uses peak detection on a TS map to find new source candidates. The procedure for adding new sources at each iteration is as follows:\n",
    "\n",
    "* Generate a TS map for the test source model defined with the model argument.\n",
    "* Identify peaks with sqrt(TS) > sqrt_ts_threshold and an angular distance of at least min_separation from a higher amplitude peak in the map.\n",
    "* Order the peaks by TS and add a source at each peak starting from the highest TS peak. Set the source position by fitting a 2D parabola to the log-likelihood surface around the peak maximum. After adding each source, re-fit its spectral parameters.\n",
    "* Add sources at the N highest peaks up to N = sources_per_iter.\n",
    "\n",
    "Source finding is repeated up to max_iter iterations or until no peaks are found in a given iteration. Sources found by the method are added to the model and given designations PS JXXXX.X+XXXX according to their position in celestial coordinates.\n",
    "\n",
    "This may take a few minutes.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "First, free all the sources.\n",
    "\n",
    "Then, define a model with a `SpatialModel` = `PointSource` and an `Index` = 2.0.\n",
    "\n",
    "Finally, find new sources using this model, setting the `sqrt_ts_threshold` to 5, the `min_separation` to 0.2 degrees, and the `tsmap_fitter` to 'tsmap', storing the result in an object called `findsource26`.\n",
    "\n",
    "**[3 marks]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gta.print_model()\n",
    "gta.write_roi('SMC_relext_TS25',make_plots=True,save_model_map=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "How many new sources were found?\n",
    "\n",
    "*-* **your answer here**\n",
    "\n",
    "**[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsmap_relext = gta.tsmap(prefix='TSmap_relext_TS25',make_plots=True,write_fits=True,write_npy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ROIPlotter(tsmap_relext['sqrt_ts'],roi=gta.roi).plot(levels=[0,3,5,7],vmin=0,vmax=6,subplot=121,cmap='magma')\n",
    "plt.gca().set_title('Sqrt(TS)')\n",
    "ROIPlotter(tsmap_relext['npred'],roi=gta.roi).plot(vmin=0,vmax=100,subplot=122,cmap='magma')\n",
    "plt.gca().set_title('NPred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_relext = gta.residmap('TSmap_relext_TS26',model={'SpatialModel' : 'PointSource', 'Index' : 2.0},write_fits=True,write_npy=True,make_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ROIPlotter(resid_relext['data'],roi=gta.roi).plot(vmin=50,vmax=400,subplot=121,cmap='magma')\n",
    "plt.gca().set_title('Data')\n",
    "ROIPlotter(resid_relext['model'],roi=gta.roi).plot(vmin=50,vmax=400,subplot=122,cmap='magma')\n",
    "plt.gca().set_title('Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ROIPlotter(resid_relext['sigma'],roi=gta.roi).plot(vmin=-5,vmax=5,levels=[-5,-3,3,5],subplot=121,cmap='RdBu_r')\n",
    "plt.gca().set_title('Significance')\n",
    "ROIPlotter(resid_relext['excess'],roi=gta.roi).plot(vmin=-100,vmax=100,subplot=122,cmap='RdBu_r')\n",
    "plt.gca().set_title('Excess')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Looking at the significance and excess maps once the SMC extension and the new sources have been added, is the new model a good fit to the data? Why?\n",
    "\n",
    "*-* **your answer here**\n",
    "\n",
    "**[2 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sed Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sed() method computes a spectral energy distribution (SED) by performing independent fits for the flux normalization of a source in bins of energy. The normalization in each bin is fit using a power-law spectral parameterization with a fixed index. The value of this index can be set with the bin_index parameter or allowed to vary over the energy range according to the local slope of the global spectral model (with the use_local_index parameter).\n",
    "\n",
    "The free_background, free_radius, and cov_scale parameters control how nuisance parameters are dealt with in the fit. By default the method will fix the parameters of background components ROI when fitting the source normalization in each energy bin (free_background=False). Setting free_background=True will profile the normalizations of all background components that were free when the method was executed. In order to minimize overfitting, background normalization parameters are constrained with priors taken from the global fit. The strength of the priors is controlled with the cov_scale parameter. A larger (smaller) value of cov_scale applies a weaker (stronger) constraint on the background amplitude. Setting cov_scale=None performs an unconstrained fit without priors.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Fix all the sources in the model (i.e. set `free` to `False` for all the sources).\n",
    "\n",
    "Then free all the sources within 3 degrees of the first source.\n",
    "\n",
    "Finally, compute the SED the first source in the ROI, storing the result in an object called `sedsmc`, using a `bin_index` of 2.2 and logarithmic energy bins, writing the output to a file called 'sedSMC.fits', specifying that plots should be made and that both `npy` and `fits` files should be written.\n",
    "\n",
    "**[3 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Print out the minimum, maximum, and reference energies of the energy bins.\n",
    "\n",
    "Print out the fluxes, the errors in the fluxes the E^2 dN/dE values, the 95% upper limits, and the TS values.\n",
    "\n",
    "**[8 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E^2 x Differential flux ULs in each bin in units of MeV cm^{-2} s^{-1}\n",
    "print(sedsmc['e2dnde_ul95'])\n",
    "\n",
    "e2dnde_scan = sedsmc['norm_scan']*sedsmc['ref_e2dnde'][:,None]\n",
    "\n",
    "for i, item in enumerate(e2dnde_scan): \n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    plt.plot(e2dnde_scan[i],sedsmc['dloglike_scan'][i]-np.max(sedsmc['dloglike_scan'][i]))\n",
    "    plt.gca().set_ylim(-5,1)\n",
    "    plt.gca().axvline(sedsmc['e2dnde_ul95'][i],color='k')\n",
    "    plt.gca().axhline(-2.71/2.,color='r')\n",
    "    plt.ylabel(r'$\\Delta \\log(L)$')\n",
    "    plt.xlabel(r'$E^2 dN/dE$ (MeV cm$^{-2}$s$^{-2})$')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(14,4))\n",
    "ylim=[1E-7,1E-5]\n",
    "fig.add_subplot(121)\n",
    "SEDPlotter(sedsmc).plot()\n",
    "plt.gca().set_ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(14,4))\n",
    "fig.add_subplot(121)\n",
    "SEDPlotter(sedsmc).plot(showlnl=True,ylim=ylim)\n",
    "plt.gca().set_ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Why do some of the data points have error bars and some have arrows pointing downwards? How does the SED plotter determine which one to use?\n",
    "\n",
    "*-* **your answer here**\n",
    "\n",
    "**[2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "sed_tab = Table.read('SMC_data/sedSMC.fits')\n",
    "sed_tab.write('SMC_data/SMC_sed.ecsv',exclude_names=['norm_scan','dloglike_scan'],overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check\n",
    "\n",
    "Before you submit your work you should make a few checks that everything works fine.\n",
    "\n",
    "1. Save your notebook as a PDF (File->Save and Export Notebook As->PDF). This document will help you debugging in the next step. (Note: If this doesn't work, save it as an HTML file, then print the HTML file to a PDF.)\n",
    "2. Restart the kernel and rerun the entire notebook (Kernel->Restart & Run All). This will delete all variables (but not your code) and rerun the notebook in one go. If this does not go through the end (i.e. you do not see the output of the next cell) then you have to fix it. You will see at which cell the run stopped. A common mistake is using a variable that is defined only at a later stage.\n",
    "3. You think you fixed everything? Redo step 2 (Kernel->Restart & Run All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a\\bYa\\boa\\bua\\b a\\baa\\bra\\bea\\b a\\bra\\bea\\baa\\bda\\bya\\b a\\bta\\boa\\b a\\bsa\\bua\\bba\\bma\\bia\\bta\\b.a\\b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see the output of the last cell without explicitly running it? Then the notebook goes through with one kernel restart. You can proceed to submission.\n",
    "You do not see the output? Go back to step 2 above.\n",
    "\n",
    "The jupyter notebook goes through all cells with one Kernel Restart & Run all.    **[1 mark]**\n",
    "\n",
    "## Submission\n",
    "\n",
    "You have to download and submit 3 files, the jupyter notebook and the two data files.\n",
    "- Jupyter notebook. File->Download As->Notebook (.ipynb). Save this file on your disk.\n",
    "- PDF (File->Save and Export Notebook As->PDF) (You can also export notebook as HTML and then print the HTML to a PDF.)\n",
    "- The flux point file (```SMC_sed.ecsv```)\n",
    "\n",
    "\n",
    "Congratulations. You have succesfully completed your TeV Data Analysis project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
